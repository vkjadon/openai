{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1HC6W7uWA5wfNkRTIBdAdtLOUpBr-sdKv",
      "authorship_tag": "ABX9TyOjxz4GOVHS2LpjL9lgdt6t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vkjadon/openai/blob/main/05oai_evaluator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can load the api key from `.env` file by importing `load_dotenv` method of `dotenv` package. We can install `dotenv` package as\n",
        "\n",
        "> `pip install python-dotenv`\n",
        "\n",
        "> `from dotenv import load_dotenv, find_dotenv`\n",
        "\n",
        "`find_dotenv()` : This function searches up the directory tree from your current working directory until it locates the .env file.\n",
        "\n",
        "`load_dotenv()` : This function reads the variables from the found .env file and loads them into your Python process's environment variables (specifically, os.environ)."
      ],
      "metadata": {
        "id": "f12H7lJThMYa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7kQ8DBuhG2F"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "load_dotenv(find_dotenv())\n",
        "\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In case you are running the code on Google Colab, add your \"OPENAI_API_KEY\" key in the `Secrets` of the colab environment and call instantiate the `OpenAI` object as below"
      ],
      "metadata": {
        "id": "frLwrYWxhRWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q faiss-cpu pypdf tiktoken"
      ],
      "metadata": {
        "id": "ox-HJvJmRr_x"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "client = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))"
      ],
      "metadata": {
        "id": "U5tQM175hUSe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "pdf_path = list(uploaded.keys())[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "lHN3x3SoSIX8",
        "outputId": "587e0a57-8b42-4b86-c94a-777b77daa777"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1034afae-f404-4945-a03f-4a96eebdbe8c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1034afae-f404-4945-a03f-4a96eebdbe8c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Chap-07-knucckle and cotter.pdf to Chap-07-knucckle and cotter.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pypdf import PdfReader\n",
        "\n",
        "reader = PdfReader(pdf_path)\n",
        "\n",
        "text = \"\"\n",
        "for page in reader.pages:\n",
        "    text += page.extract_text()\n",
        "\n",
        "print(text[:1000])  # preview\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6s1Lc-EShEo",
        "outputId": "0f6e8d08-1bd7-44cb-eeef-fc7e350be5ba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/G43/G6F/G74/G74/G65/G72/G20/G6A/G6F/G69/G6E/G74/G20/G69/G73/G20/G75/G73/G65/G64/G20/G77/G68/G65/G6E/G20/G74/G68/G65/G20/G6D/G65/G6D/G62/G65/G72/G73/G20/G61/G72/G65/G20/G73/G75/G62/G6A/G65/G63/G74/G65/G64/G20/G74/G6F/G20/G61/G78/G69/G61/G6C/G20/G74/G65/G6E/G73/G69/G6C/G65/G20/G6F/G72/G20/G63/G6F/G6D/G70/G72/G65/G73/G73/G69/G76/G65/G20/G6C/G6F/G61/G64/G73/G2C/G20/G65/G61/G73/G79\n",
            "/G61/G73/G73/G65/G6D/G62/G6C/G79/G20/G61/G6E/G64/G20/G64/G69/G73/G61/G73/G73/G65/G6D/G62/G6C/G79/G20/G69/G73/G20/G72/G65/G71/G75/G69/G72/G65/G64/G2C/G20/G6E/G6F/G20/G72/G65/G6C/G61/G74/G69/G76/G65/G20/G6D/G6F/G74/G69/G6F/G6E/G20/G62/G65/G74/G77/G65/G65/G6E/G20/G74/G68/G65/G20/G74/G77/G6F/G20/G66/G61/G73/G74/G65/G6E/G65/G64/G20/G6D/G65/G6D/G62/G65/G72/G73\n",
            "/G28/G72/G6F/G64/G73/G29/G20/G69/G73/G20/G64/G65/G73/G69/G72/G65/G64/G20/G61/G6E/G64/G20/G74/G68/G65/G20/G61/G78/G65/G73/G20/G6F/G66/G20/G74/G77/G6F/G20/G72/G6F/G64/G73/G20/G61/G72/G65/G20/G63/G6F/G6C/G6C/G69/G6E/G65/G61/G72/G2E/G20/G54/G68/G65/G20/G63/G6F/G74/G\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_text(text, chunk_size=800, overlap=100):\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(text):\n",
        "        end = start + chunk_size\n",
        "        chunks.append(text[start:end])\n",
        "        start = end - overlap\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "Mv7l3s1UTL5O"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = chunk_text(text)\n",
        "print(\"Total chunks:\", len(chunks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2Ut3xSQTPwX",
        "outputId": "c1870ca9-1ae3-4321-cf22-f1e2e226f822"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total chunks: 142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "drKy390kTfdk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embeddings(texts):\n",
        "    response = client.embeddings.create(\n",
        "        model=\"text-embedding-3-small\",\n",
        "        input=texts\n",
        "    )\n",
        "    return np.array([e.embedding for e in response.data])"
      ],
      "metadata": {
        "id": "9NeJAhKgTay3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_embeddings = get_embeddings(chunks)\n",
        "print(chunk_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCnx-KjXTd3v",
        "outputId": "af968651-5ecd-40b7-bb58-9e3114633d81"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(142, 1536)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FAISS (Facebook AI Similarity Search) is an open-source library for efficient similarity search and clustering of dense, high-dimensional vectors. It is used to quickly find items in massive datasets that are \"similar\" to a given query item, solving performance bottlenecks that traditional databases face when dealing with unstructured data like images or text embeddings."
      ],
      "metadata": {
        "id": "peGgw42zUaZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "\n",
        "dimension = chunk_embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(chunk_embeddings)\n",
        "\n",
        "print(\"FAISS index size:\", index.ntotal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hFDJANNTvES",
        "outputId": "72e5e950-7fe8-4f3a-944d-befe45389b50"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index size: 142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_context(query, k=4):\n",
        "    query_embedding = get_embeddings([query])\n",
        "    distances, indices = index.search(query_embedding, k)\n",
        "    return \"\\n\\n\".join([chunks[i] for i in indices[0]])"
      ],
      "metadata": {
        "id": "3A_nzMRioCwp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_context(query):\n",
        "    retrieved = retrieve_context(query)\n",
        "    return \"\\n\\n\".join(retrieved)"
      ],
      "metadata": {
        "id": "rNXO3mWXu-89"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asked_questions = []\n",
        "def generate_unique_question(topic, difficulty=\"medium\"):\n",
        "    context = build_context(topic)\n",
        "\n",
        "    previous_questions = \"\\n\".join(asked_questions) if asked_questions else \"None\"\n",
        "\n",
        "    response = client.responses.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        input=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a university examiner.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"developer\",\n",
        "                \"content\": (\n",
        "                    \"Generate ONE new exam question \"\n",
        "                    \"that has NOT been asked before in this session. \"\n",
        "                    \"Do not repeat or rephrase previous questions.\"\n",
        "                )\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"\"\"\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Previously asked questions:\n",
        "{previous_questions}\n",
        "\n",
        "Topic:\n",
        "{topic}\n",
        "\"\"\"\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    question = response.output_text.strip()\n",
        "    asked_questions.append(question)\n",
        "\n",
        "    return question\n"
      ],
      "metadata": {
        "id": "NB3YfsfcoHsi"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = generate_unique_question(\"Cotter Joint\")\n",
        "print(\"QUESTION:\", question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyrsJc2uoRRD",
        "outputId": "163e8d05-3faa-4445-986e-7665ca53597a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QUESTION: Using the dimensional symbols and proportions described in the context, derive an expression for the shear area of the cotter in terms of the rod diameter (d), cotter width (b), and cotter thickness (t). Discuss how variations in each parameter would affect the strength and durability of the cotter joint under shear loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_answer(question, student_answer, max_marks=10):\n",
        "    context = build_context(question)\n",
        "\n",
        "    response = client.responses.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        input=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a strict and fair examiner.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"developer\",\n",
        "                \"content\": (\n",
        "                    \"Evaluate the student answer using ONLY the provided context. \"\n",
        "                    \"Do NOT use external knowledge.\\n\\n\"\n",
        "                    \"Follow this rubric:\\n\"\n",
        "                    \"1. Concept correctness\\n\"\n",
        "                    \"2. Coverage of key points\\n\"\n",
        "                    \"3. Technical accuracy\\n\"\n",
        "                    \"4. Clarity of explanation\\n\\n\"\n",
        "                    f\"Assign marks out of {max_marks}. \"\n",
        "                    \"Return output in JSON with keys: \"\n",
        "                    \"score, strengths, missing_points, feedback.\"\n",
        "                )\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"\"\"\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Student Answer:\n",
        "{student_answer}\n",
        "\"\"\"\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.output_text\n"
      ],
      "metadata": {
        "id": "Sb_-80_dw1cC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_answer = input(\"Enter student answer:\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsTLKFIsxCfd",
        "outputId": "a44dacc6-134a-46f2-c81e-ba9bad83ecb9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter student answer:\n",
            "Shear Area = 2 * pi * t * b\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation = evaluate_answer(question, student_answer)\n",
        "print(\"EVALUATION RESULT:\\n\", evaluation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NagI8laKxTbC",
        "outputId": "67a05b1e-8f27-4558-8ce8-c7bc4d3d3bd7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVALUATION RESULT:\n",
            " ```json\n",
            "{\n",
            "  \"score\": 2,\n",
            "  \"strengths\": [\n",
            "    \"Student attempts to provide a formula for shear area, indicating awareness of relevant parameters (t and b).\"\n",
            "  ],\n",
            "  \"missing_points\": [\n",
            "    \"The expression for shear area should properly include the rod diameter (d), as the cotter shear planes relate to d and the cotter dimensions.\",\n",
            "    \"The coefficient '2 * pi' is incorrect; shear area here is related to planar areas, not circular or cylindrical surface area.\",\n",
            "    \"Lack of explanation about how shear area is derived geometrically from the cotter joint dimensions in the context.\",\n",
            "    \"No discussion on how variations in rod diameter (d), cotter width (b), and thickness (t) affect strength and durability.\",\n",
            "    \"No explanation tying the dimensions to strength and durability under shear loading.\"\n",
            "  ],\n",
            "  \"feedback\": \"The provided formula for shear area '2 * pi * t * b' is incorrect based on the context's dimensional symbols and proportions. The shear area of the cotter is typically the area where shear occurs on the cotter faces, which involves the product of cotter thickness (t) and width (b), multiplied by the number of shear planes (usually two). The rod diameter (d) affects the length of the shear plane and must feature in the expression. Additionally, the answer lacks discussion on how varying each parameter (d, b, t) influences the cotter joint's strength and durability under shear loading, which is critical. Please revise the formula considering the planar shear faces and provide a clear explanation of the impact of each variable.\"\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    }
  ]
}