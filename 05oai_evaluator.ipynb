{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1HC6W7uWA5wfNkRTIBdAdtLOUpBr-sdKv",
      "authorship_tag": "ABX9TyNHga6SfNWnKFKHK7/c8hKz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vkjadon/openai/blob/main/05oai_evaluator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can load the api key from `.env` file by importing `load_dotenv` method of `dotenv` package. We can install `dotenv` package as\n",
        "\n",
        "> `pip install python-dotenv`\n",
        "\n",
        "> `from dotenv import load_dotenv, find_dotenv`\n",
        "\n",
        "`find_dotenv()` : This function searches up the directory tree from your current working directory until it locates the .env file.\n",
        "\n",
        "`load_dotenv()` : This function reads the variables from the found .env file and loads them into your Python process's environment variables (specifically, os.environ)."
      ],
      "metadata": {
        "id": "f12H7lJThMYa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7kQ8DBuhG2F"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "load_dotenv(find_dotenv())\n",
        "\n",
        "client = OpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In case you are running the code on Google Colab, add your \"OPENAI_API_KEY\" key in the `Secrets` of the colab environment and call instantiate the `OpenAI` object as below"
      ],
      "metadata": {
        "id": "frLwrYWxhRWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q faiss-cpu pypdf tiktoken"
      ],
      "metadata": {
        "id": "ox-HJvJmRr_x",
        "outputId": "c104b274-e7bc-4aae-fa05-d6d07ea1be57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.2/328.2 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "client = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))"
      ],
      "metadata": {
        "id": "U5tQM175hUSe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "pdf_path = list(uploaded.keys())[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "lHN3x3SoSIX8",
        "outputId": "941d8e3c-6c88-4cf4-aae6-4d950c672059"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-228af457-864d-43a8-85fb-c4992a225eeb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-228af457-864d-43a8-85fb-c4992a225eeb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving download.pdf to download.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pypdf import PdfReader\n",
        "\n",
        "reader = PdfReader(pdf_path)\n",
        "\n",
        "text = \"\"\n",
        "for page in reader.pages:\n",
        "    text += page.extract_text()\n",
        "\n",
        "print(text[:1000])  # preview\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6s1Lc-EShEo",
        "outputId": "4579ad4c-07c0-4ced-cf23-28b836e1cfc6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Different types of AI\n",
            "Estimated time: 10 minutes\n",
            "Introduction\n",
            "Artiﬁcial intelligence (AI) encompasses a range of systems designed to mimic, enhance, or exceed human capabilities. AI can be categorized based on its capabilitiesand functionalities. Understanding these types and their capabilities highlights the diverse applications and potential of AI technologies.\n",
            "Objectives\n",
            "After completing this reading, you will be able to:\n",
            "Explain the types of artiﬁcial intelligence based on their functionalities.\n",
            "Explore the capabilities of each type of artiﬁcial intelligence.\n",
            "AI types\n",
            "1. Diagnostic/descriptive AI\n",
            "Diagnostic or descriptive AI focuses on assessing the correctness of behavior by analyzing historical data to understand what happened and why. This type ofAI is instrumental in identifying patterns and trends, performing comparative analyses, and conducting root cause analyses.\n",
            "Capabilities:\n",
            "Scenario planning: Helps in creating different future scenarios based on historical data.\n",
            "Pattern/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chunk_text(text, chunk_size=800, overlap=100):\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(text):\n",
        "        end = start + chunk_size\n",
        "        chunks.append(text[start:end])\n",
        "        start = end - overlap\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "Mv7l3s1UTL5O"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = chunk_text(text)\n",
        "print(\"Total chunks:\", len(chunks))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2Ut3xSQTPwX",
        "outputId": "de5dcbad-8dfd-4b60-b78d-49d46fad0284"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total chunks: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "drKy390kTfdk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embeddings(texts):\n",
        "    response = client.embeddings.create(\n",
        "        model=\"text-embedding-3-small\",\n",
        "        input=texts\n",
        "    )\n",
        "    return np.array([e.embedding for e in response.data])"
      ],
      "metadata": {
        "id": "9NeJAhKgTay3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_embeddings = get_embeddings(chunks)\n",
        "print(chunk_embeddings.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCnx-KjXTd3v",
        "outputId": "a33ef3e7-c278-4948-c94e-824f4f70a316"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11, 1536)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FAISS (Facebook AI Similarity Search) is an open-source library for efficient similarity search and clustering of dense, high-dimensional vectors. It is used to quickly find items in massive datasets that are \"similar\" to a given query item, solving performance bottlenecks that traditional databases face when dealing with unstructured data like images or text embeddings."
      ],
      "metadata": {
        "id": "peGgw42zUaZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "\n",
        "dimension = chunk_embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(chunk_embeddings)\n",
        "\n",
        "print(\"FAISS index size:\", index.ntotal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hFDJANNTvES",
        "outputId": "04a93d7d-d548-4ecf-b8b4-2d4a698c7e0a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index size: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_context(query, k=4):\n",
        "    query_embedding = get_embeddings([query])\n",
        "    distances, indices = index.search(query_embedding, k)\n",
        "    return \"\\n\\n\".join([chunks[i] for i in indices[0]])"
      ],
      "metadata": {
        "id": "3A_nzMRioCwp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_context(query):\n",
        "    retrieved = retrieve_context(query)\n",
        "    return \"\\n\\n\".join(retrieved)"
      ],
      "metadata": {
        "id": "rNXO3mWXu-89"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asked_questions = []\n",
        "def generate_unique_question(topic, difficulty=\"medium\"):\n",
        "    context = build_context(topic)\n",
        "\n",
        "    previous_questions = \"\\n\".join(asked_questions) if asked_questions else \"None\"\n",
        "\n",
        "    response = client.responses.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        input=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a university examiner.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"developer\",\n",
        "                \"content\": (\n",
        "                    \"Generate ONE new exam question \"\n",
        "                    \"that has NOT been asked before in this session. \"\n",
        "                    \"Do not repeat or rephrase previous questions.\"\n",
        "                )\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"\"\"\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Previously asked questions:\n",
        "{previous_questions}\n",
        "\n",
        "Topic:\n",
        "{topic}\n",
        "\"\"\"\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    question = response.output_text.strip()\n",
        "    asked_questions.append(question)\n",
        "\n",
        "    return question\n"
      ],
      "metadata": {
        "id": "NB3YfsfcoHsi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = generate_unique_question(\"Types of AI\")\n",
        "print(\"QUESTION:\", question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyrsJc2uoRRD",
        "outputId": "1cf1d5e6-9a46-489f-b843-b1b68e07a5a2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QUESTION: Discuss the differences between Diagnostic/Descriptive AI and Prescriptive AI in terms of their objectives and data utilization. How can these differences influence decision-making processes in a business environment?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_answer(question, student_answer, max_marks=10):\n",
        "    context = build_context(question)\n",
        "\n",
        "    response = client.responses.create(\n",
        "        model=\"gpt-4.1-mini\",\n",
        "        input=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are a strict and fair examiner.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"developer\",\n",
        "                \"content\": (\n",
        "                    \"Evaluate the student answer using ONLY the provided context. \"\n",
        "                    \"Do NOT use external knowledge.\\n\\n\"\n",
        "                    \"Follow this rubric:\\n\"\n",
        "                    \"1. Concept correctness\\n\"\n",
        "                    \"2. Coverage of key points\\n\"\n",
        "                    \"3. Technical accuracy\\n\"\n",
        "                    \"4. Clarity of explanation\\n\\n\"\n",
        "                    f\"Assign marks out of {max_marks}. \"\n",
        "                    \"Return output in JSON with keys: \"\n",
        "                    \"score, strengths, missing_points, feedback.\"\n",
        "                )\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"\"\"\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Student Answer:\n",
        "{student_answer}\n",
        "\"\"\"\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.output_text\n"
      ],
      "metadata": {
        "id": "Sb_-80_dw1cC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_answer = input(\"Enter student answer:\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsTLKFIsxCfd",
        "outputId": "64fdfc32-129e-4b84-9b7e-5bf64bf3ef98"
      },
      "execution_count": 20,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter student answer:\n",
            "AI is machine with brain\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation = evaluate_answer(question, student_answer)\n",
        "print(\"EVALUATION RESULT:\\n\", evaluation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NagI8laKxTbC",
        "outputId": "b9723adc-7cc9-4ee7-aa95-6dddc3b253b9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVALUATION RESULT:\n",
            " {\n",
            "  \"score\": 1,\n",
            "  \"strengths\": \"The student attempts to relate AI to a machine with a brain, which loosely hints at AI's capability to mimic human-like functions.\",\n",
            "  \"missing_points\": \"The response does not address the differences between Diagnostic/Descriptive AI and Prescriptive AI, their objectives, or how they utilize data. Additionally, it fails to explain how these differences influence decision-making processes in a business context.\",\n",
            "  \"feedback\": \"Your answer is very limited and does not cover the required aspects of the question. You need to clearly explain how Diagnostic/Descriptive AI focuses on analyzing historical data to understand past behaviors and outcomes, while Prescriptive AI focuses on determining the optimal course of action by providing recommendations based on data analysis. Additionally, you should discuss how these differences affect business decisions, with Diagnostic AI helping understand what happened and why, and Prescriptive AI providing actionable strategies to achieve desired results. Please provide a more detailed and focused response next time.\"\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}